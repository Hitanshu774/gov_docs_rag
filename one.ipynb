{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "17f9419f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0efe1bf",
   "metadata": {},
   "source": [
    "# Using langchain loaders to load dataset from local directory -> corpus.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148e4f5",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Each JSONL line is being passed as a full Python dict\n",
    "ðŸ‘‰ LangChain expects Document.page_content to be a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0d71e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 973 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=\"corpus.jsonl\",\n",
    "    # jq_schema=\"._id\",\n",
    "    jq_schema=\".text\",\n",
    "    json_lines=True\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "640fe7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Privileged\" Nominations Every year the Senate routinely considers whether to give its advice and consent to hundreds of nominations submitted by the President. From start to finish, the confirmation process can be a lengthy one, even for relatively noncontroversial nominees. Each nomination is typically referred to one or more committees having subject matter jurisdiction over the position. Committees may bear a significant workload in examining nomineesÃ¢\\x80\\x94often including questionnaires, option'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(documents[0]))\n",
    "documents[0].page_content[:500]  # Print the first 500 characters of the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "89dac5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'C:\\\\Users\\\\hitan\\\\OneDrive\\\\Desktop\\\\me space\\\\Projects_RAG\\\\gov_docs_rag\\\\gov_docs_rag\\\\corpus.jsonl',\n",
       " 'seq_num': 5}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[4].metadata  # Print the metadata of the first document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4ce90839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 109064 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "textsplitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "chunks = textsplitter.split_documents(documents)\n",
    "print(f\"Split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2e654c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Privileged\" Nominations Every year the Senate routinely considers whether to give its advice and consent to hundreds of nominations submitted by the President. From start to finish, the confirmation process can be a lengthy one, even for relatively noncontroversial nominees. Each nomination is typically referred to one or more committees having subject matter jurisdiction over the position. Committees may bear a significant workload in examining nomineesÃ¢\\x80\\x94often including questionnaires,'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].page_content # Print the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "15c232ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = HuggingFaceEmbeddings(model_name = \"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "# db_name = \"vector_db\"\n",
    "\n",
    "# if os.path.exists(db_name):\n",
    "#     Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "    \n",
    "# vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "# print(vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7b5618a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## relaoding the vectordb without re-embedding\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\"\n",
    ")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory=\"./vector_db\",\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32c4ce",
   "metadata": {},
   "source": [
    "setting up langchain objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "92a961d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY: 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\n",
      "Starts with sk-or-: True\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "key = os.getenv(\"api-key\")\n",
    "print(\"KEY:\", key)\n",
    "print(\"Starts with sk-or-:\", key.startswith(\"sk-or-\") if key else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7904d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})\n",
    "llm = ChatOpenAI(model_name=\"mistralai/devstral-2512:free\", \n",
    "                 openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "                 temperature=0.3,\n",
    "                 max_tokens=512,\n",
    "                 openai_api_key=os.getenv(\"api-key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e2092ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9ee824a8-0899-4f42-b359-989b22099a94', metadata={'source': 'C:\\\\Users\\\\hitan\\\\OneDrive\\\\Desktop\\\\me space\\\\Projects_RAG\\\\gov_docs_rag\\\\gov_docs_rag\\\\corpus.jsonl', 'seq_num': 274}, page_content='Enterprise Acquisition Services. Services Provided: Computing Services operates the DISA Data Centers, which provide mainframe and server processing operations, data storage, and other information technology services and support across the Department of Defense (DOD). Telecommunications Services provides secure telecommunications services, including the Defense Information Systems Network. Enterprise Acquisitions Services provides contracting services for information technology and telecommunications acquisitions from the commercial sector and contracting support to the Defense Information Systems Network programs and other customers through DISAâ€™s Defense Information Technology Contracting Organization. Approach to Allocating Costs: The Defense Information Systems Agency (DISA) groups its services by the costs associated with providing them. These costs are specific to the service being provided and are influenced by factors such as the cost of equipment used to provide the service.'),\n",
       " Document(id='87bfa4e6-b50a-4070-83cc-905c5c107622', metadata={'seq_num': 879, 'source': 'C:\\\\Users\\\\hitan\\\\OneDrive\\\\Desktop\\\\me space\\\\Projects_RAG\\\\gov_docs_rag\\\\gov_docs_rag\\\\corpus.jsonl'}, page_content='contracts achieved desired outcomes. While DOD agreed with the recommendation and developed a template for the military departments to use to collect relevant information, it is still gathering updates from the military departments about the status of this effort. Contracting for Major Defense Acquisition Programs DOD acquires MDAPs through the Defense Acquisition System, which implements an adaptive acquisition framework that allows DOD officials to develop acquisition strategies and employ acquisition processes that match the characteristics of the capability being acquired. The pathway for acquiring major capabilities generally includes four phases, three of which we focus on in this report: (1) technology maturation and risk reduction; (2) engineering and manufacturing development; and (3) production and deployment. Programs typically complete a series of milestone reviews and other key decision points that authorize entry into a new acquisition phase, as illustrated in figure 2.'),\n",
       " Document(id='42bec451-626c-46b8-929f-c5affcbf58a4', metadata={'seq_num': 4, 'source': 'C:\\\\Users\\\\hitan\\\\OneDrive\\\\Desktop\\\\me space\\\\Projects_RAG\\\\gov_docs_rag\\\\gov_docs_rag\\\\corpus.jsonl'}, page_content='Background DOD acquires new weapon systems for its warfighters through a management process known as the Defense Acquisition System. This system is implemented by two key acquisition policies: DOD Directive 5000.01, which establishes the overarching framework for the Defense Acquisition System; and DOD Instruction 5000.02, which provides detailed procedures for the operation of the Defense Acquisition System and the management of acquisition programs. These policy documents establish the guiding principles for all aspects of the DOD acquisition process. Additionally, each of the military services has its own acquisition policies which incorporate and enhance the DOD acquisition guidance. Figure 2 depicts DODâ€™s acquisition process beginning with Milestone A in general terms. Several entities in the Office of the Secretary of Defense and the military departments play a role in the oversight of DOD weapon system acquisition programs, including the following: The Under Secretary of Defense'),\n",
       " Document(id='0c9a07d2-2660-4917-98f5-e0e7a2d1f418', metadata={'source': 'C:\\\\Users\\\\hitan\\\\OneDrive\\\\Desktop\\\\me space\\\\Projects_RAG\\\\gov_docs_rag\\\\gov_docs_rag\\\\corpus.jsonl', 'seq_num': 13}, page_content='required in traditional mechanisms, such as contracts or grants. Congress also required that DOD establish a panel in the National Defense Authorization Act for Fiscal Year 2016, referred to as the â€œSection 809 Panel,â€ to identify ways to streamline and improve the defense acquisition system. The panel issued its final report in January 2019, which, together with its earlier reports, included a wide range of recommendations aimed at changing the overall structure and operations of defense acquisition. DOD Acquisition Programs and Authorities DOD acquisition policy defines an acquisition program as a directed, funded effort that provides a new, improved, or continuing materiel, weapon, or information system, or a service capability in response to an approved need. DOD Directive 5000.01, The Defense Acquisition System, provides management principles and mandatory policies and procedures for managing all acquisition programs. Oversight levels and procedures for DODâ€™s acquisition programs'),\n",
       " Document(id='4acc2bbb-6c51-488e-9a84-6ed4a261dadb', metadata={'source': 'C:\\\\Users\\\\hitan\\\\OneDrive\\\\Desktop\\\\me space\\\\Projects_RAG\\\\gov_docs_rag\\\\gov_docs_rag\\\\corpus.jsonl', 'seq_num': 13}, page_content='because technologies were considered mature by the Office of the Secretary of Defense and an independent review team, respectively. Figure 1 illustrates the key milestones associated with the defense acquisition system. DODâ€™s acquisition policy encourages tailoring the acquisition process, including tailoring of documentation or information requirements. In previous work, we identified opportunities for DOD to tailor the documentation and oversight needed for major defense acquisition programs. In 2015, we found that 24 acquisition programs we surveyed spent, on average, over 2 years completing up to 49 information requirements for their most recent milestone decision. We found that DODâ€™s review process was a key factor that influenced the time needed to complete the information requirements. In total, the requirements averaged 5,600 staff days to document, yet acquisition officials considered only about half of the requirements as high value. We recommended that DOD eliminate reviews')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is Defense Acquisition System?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cecbeb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The **Defense Acquisition System (DAS)** is the structured process used by the **U.S. Department of Defense (DoD)** to acquire weapons, equipment, services, and other capabilities needed to support national defense. It is governed by **DoD Directive 5000.01** and **DoD Instruction 5000.02**, which outline policies and procedures for acquiring defense systems efficiently, affordably, and effectively.\\n\\n### **Key Components of the Defense Acquisition System:**\\n1. **Acquisition Framework**\\n   - The system follows a **phased approach** (from concept to disposal) to manage risk, cost, and performance.\\n   - It ensures **accountability, transparency, and oversight** throughout the acquisition lifecycle.\\n\\n2. **Acquisition Lifecycle Phases**\\n   The process is divided into **six key phases** (as per **DoD Instruction 5000.02**):\\n   - **Materiel Solution Analysis (MSA)** â€“ Identifies capabilities needed and explores potential solutions.\\n   - **Technology Maturation & Risk Reduction (TMRR)** â€“ Develops and tests technologies to reduce risks.\\n   - **Engineering & Manufacturing Development (EMD)** â€“ Finalizes system design and begins production planning.\\n   - **Production & Deployment (P&D)** â€“ Manufactures and delivers the system to users.\\n   - **Operations & Support (O&S)** â€“ Maintains and sustains the system in service.\\n   - **Disposal** â€“ Retires or disposes of the system responsibly.\\n\\n3. **Key Stakeholders**\\n   - **Acquisition Workforce** (Program Managers, Engineers, Contracting Officers)\\n   - **Military Services** (Army, Navy, Air Force, Marines, Space Force)\\n   - **Defense Agencies** (DARPA, Missile Defense Agency, etc.)\\n   - **Industry Partners** (Defense contractors like Lockheed Martin, Boeing, etc.)\\n   - **Congress & Oversight Bodies** (GAO, DoD Inspector General)\\n\\n4. **Key Principles & Policies**\\n   - **Affordability & Cost Control** â€“ Ensures programs stay within budget.\\n   - **Modular Open Systems Approach (MOSA)** â€“ Encourages interoperability and upgrades.\\n   - **Rapid Acquisition Pathways** â€“ For urgent needs (e.g., **Middle Tier Acquisition (MTA)** for rapid prototyping).\\n   - **', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 512, 'prompt_tokens': 9, 'total_tokens': 521, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1768467444-IJ27r7O129QPCcUeHuQT', 'service_tier': None, 'finish_reason': 'length', 'logprobs': None}, id='run--aa5a7403-aac5-4ab1-83d6-db6b705ca2db-0', usage_metadata={'input_tokens': 9, 'output_tokens': 512, 'total_tokens': 521, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is Defense Acquisition System?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "28f11fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a knowledgeable, strict assistant representing the details from government documents.\n",
    "You are chatting with a user about government policies.\n",
    "If relevant, use the given context to answer any question.\n",
    "If you don't know the answer, say so.\n",
    "Context:\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "742dc0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, history):\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)####################\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    response = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=question)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "799a3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer_question(\"which program had an estimated combined value of $20 billion?\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bc24cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gr.ChatInterface(answer_question).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "49f5029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1 = ChatOpenAI(\n",
    "    model=\"mistralai/mistral-7b-instruct:free\",  # example\n",
    "    openai_api_key=os.getenv(\"api-key\"),\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bfe046a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create another llm instance with different model and test the performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f74530f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DETAILED RAG SYSTEM EVALUATION\n",
      "================================================================================\n",
      "Total tests to run: 10\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Test #1\n",
      "================================================================================\n",
      "Question: How does the MHPI funding structure balance DoD housing policy goals with private-sector incentives, and what inherent risk does this create?\n",
      "Keywords: ['MHPI', 'DoD housing policy', 'private-sector incentives', 'revenue allocation', 'maintenance reserves', 'developer profits', 'long-term risk']\n",
      "Category: direct_fact\n",
      "Reference Answer: The structure prioritizes operating costs, debt service, and scheduled maintenance before allocating profits, aligning with DoD goals of sustainable, ...\n",
      "\n",
      "================================================================================\n",
      "Retrieval Evaluation\n",
      "================================================================================\n",
      "MRR: 1.0000\n",
      "nDCG: 1.0000\n",
      "Keywords Found: 1/7\n",
      "Keyword Coverage: 14.3%\n",
      "\n",
      "Retrieved Documents:\n",
      "  1. 2 for details on each military departmentâ€™s roles and responsibilities in the MHPI program. Prior GAO Work We have previously reported on DODâ€™s privatized housing program. In 2002, we reported that al...\n",
      "  2. This report examines the extent to which the Office of the Secretary of Defense (OSD) and the military departments (1) conduct oversight of privatized military housing for servicemembers and their fam...\n",
      "  3. would be implemented. According to OSD officials, as of January 2020, there are many questions surrounding the implementation of the Fiscal Year 2020 NDAA provisions. Officials told us that they have ...\n",
      "  4. Background DODâ€™s policy is to ensure that eligible personnel and their families have access to affordable, quality housing facilities and services consistent with grade and dependent status, and that ...\n",
      "  5. Background DODâ€™s policy is to ensure that eligible personnel and their families have access to affordable, quality housing facilities and services consistent with grade and dependent status, and that ...\n",
      "\n",
      "================================================================================\n",
      "Answer Evaluation\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1768521600000'}, 'provider_name': None}}, 'user_id': 'user_37LtdcNW2jd1r5aKt8p6w5QMEEI'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[146], line 294\u001b[0m\n\u001b[0;32m    291\u001b[0m         test_cases\u001b[38;5;241m.\u001b[39mappend(json\u001b[38;5;241m.\u001b[39mloads(line\u001b[38;5;241m.\u001b[39mstrip()))\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# Run detailed evaluation (first 5 tests for quick demo)\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_detailed_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;66;03m# Print summary\u001b[39;00m\n\u001b[0;32m    297\u001b[0m print_summary_report(results)\n",
      "Cell \u001b[1;32mIn[146], line 200\u001b[0m, in \u001b[0;36mrun_detailed_evaluation\u001b[1;34m(test_cases, num_tests)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer Evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 200\u001b[0m answer_result, generated_answer, retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_answer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreference_answer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeywords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerated Answer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgenerated_answer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFeedback:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00manswer_result\u001b[38;5;241m.\u001b[39mfeedback\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[146], line 93\u001b[0m, in \u001b[0;36mevaluate_answer\u001b[1;34m(question, reference_answer, keywords)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Generate answer\u001b[39;00m\n\u001b[0;32m     92\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m SYSTEM_PROMPT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m---> 93\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m generated_answer \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Evaluate accuracy (keyword matching)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    392\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 395\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    396\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    397\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    398\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    399\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    400\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    401\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    402\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    403\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    404\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    405\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1023\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1024\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    841\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 842\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    843\u001b[0m                 m,\n\u001b[0;32m    844\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    845\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    846\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    847\u001b[0m             )\n\u001b[0;32m    848\u001b[0m         )\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1091\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1092\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1093\u001b[0m     )\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1095\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1213\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_response\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1212\u001b[0m         e\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;241m=\u001b[39m raw_response\u001b[38;5;241m.\u001b[39mhttp_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m-> 1213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_response_headers\n\u001b[0;32m   1216\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1218\u001b[0m ):\n\u001b[0;32m   1219\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1208\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[0;32m   1202\u001b[0m             response,\n\u001b[0;32m   1203\u001b[0m             schema\u001b[38;5;241m=\u001b[39moriginal_schema_obj,\n\u001b[0;32m   1204\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mgeneration_info,\n\u001b[0;32m   1205\u001b[0m             output_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_version,\n\u001b[0;32m   1206\u001b[0m         )\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1208\u001b[0m         raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mwith_raw_response\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m   1209\u001b[0m         response \u001b[38;5;241m=\u001b[39m raw_response\u001b[38;5;241m.\u001b[39mparse()\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\openai\\_legacy_response.py:364\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m extra_headers[RAW_RESPONSE_HEADER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[1;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1192\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[0;32m   1190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1191\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_retention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\hitan\\anaconda3\\envs\\torch_llm\\lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1768521600000'}, 'provider_name': None}}, 'user_id': 'user_37LtdcNW2jd1r5aKt8p6w5QMEEI'}"
     ]
    }
   ],
   "source": [
    "from rag_evaluator import RAGEvaluator\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ============================================================================\n",
    "# DATA CLASSES FOR DETAILED EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class RetrievalResult:\n",
    "    \"\"\"Results from retrieval evaluation\"\"\"\n",
    "    mrr: float  # Mean Reciprocal Rank\n",
    "    ndcg: float  # Normalized Discounted Cumulative Gain\n",
    "    keywords_found: int\n",
    "    total_keywords: int\n",
    "    keyword_coverage: float  # percentage\n",
    "    retrieved_docs: List[str]\n",
    "\n",
    "@dataclass\n",
    "class AnswerResult:\n",
    "    \"\"\"Results from answer evaluation\"\"\"\n",
    "    accuracy: float  # 0-5\n",
    "    completeness: float  # 0-5\n",
    "    relevance: float  # 0-5\n",
    "    feedback: str\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_retrieval(question, keywords, k=4):\n",
    "    \"\"\"\n",
    "    Evaluate retrieval quality\n",
    "    Returns: RetrievalResult with metrics\n",
    "    \"\"\"\n",
    "    docs = retriever.invoke(question)\n",
    "    \n",
    "    # Get doc content\n",
    "    doc_contents = [doc.page_content.lower() for doc in docs]\n",
    "    combined_content = \" \".join(doc_contents)\n",
    "    \n",
    "    # Count keywords found\n",
    "    keywords_found = 0\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in combined_content:\n",
    "            keywords_found += 1\n",
    "    \n",
    "    # Calculate keyword coverage\n",
    "    keyword_coverage = (keywords_found / len(keywords) * 100) if keywords else 0\n",
    "    \n",
    "    # Calculate MRR (Mean Reciprocal Rank)\n",
    "    mrr = 0.0\n",
    "    for idx, doc in enumerate(docs):\n",
    "        doc_lower = doc.page_content.lower()\n",
    "        found_keywords = sum(1 for kw in keywords if kw.lower() in doc_lower)\n",
    "        if found_keywords > 0:\n",
    "            mrr = 1.0 / (idx + 1)\n",
    "            break\n",
    "    \n",
    "    # Calculate nDCG (simplified version)\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "    for idx in range(min(len(docs), len(keywords))):\n",
    "        doc_lower = docs[idx].page_content.lower()\n",
    "        found_keywords = sum(1 for kw in keywords if kw.lower() in doc_lower)\n",
    "        dcg += found_keywords / (idx + 1)\n",
    "        idcg += 1 / (idx + 1)\n",
    "    \n",
    "    ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "    \n",
    "    return RetrievalResult(\n",
    "        mrr=mrr,\n",
    "        ndcg=ndcg,\n",
    "        keywords_found=keywords_found,\n",
    "        total_keywords=len(keywords),\n",
    "        keyword_coverage=keyword_coverage,\n",
    "        retrieved_docs=[doc.page_content[:200] for doc in docs]\n",
    "    )\n",
    "\n",
    "def evaluate_answer(question, reference_answer, keywords):\n",
    "    \"\"\"\n",
    "    Evaluate generated answer quality\n",
    "    Returns: (AnswerResult, generated_answer, retrieved_docs)\n",
    "    \"\"\"\n",
    "    # Get retrieval\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    # Generate answer\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    response = llm1.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=question)\n",
    "    ])\n",
    "    generated_answer = response.content\n",
    "    \n",
    "    # Evaluate accuracy (keyword matching)\n",
    "    answer_lower = generated_answer.lower()\n",
    "    keywords_matched = sum(1 for kw in keywords if kw.lower() in answer_lower)\n",
    "    accuracy = (keywords_matched / len(keywords) * 5) if keywords else 5.0\n",
    "    accuracy = min(accuracy, 5.0)\n",
    "    \n",
    "    # Evaluate completeness (length and detail)\n",
    "    ref_words = len(reference_answer.split())\n",
    "    gen_words = len(generated_answer.split())\n",
    "    length_ratio = gen_words / ref_words if ref_words > 0 else 1.0\n",
    "    completeness = 5.0 if 0.7 <= length_ratio <= 1.3 else 3.0\n",
    "    \n",
    "    # Evaluate relevance (semantic similarity)\n",
    "    ref_words_set = set(reference_answer.lower().split())\n",
    "    gen_words_set = set(generated_answer.lower().split())\n",
    "    similarity = len(ref_words_set & gen_words_set) / len(ref_words_set | gen_words_set)\n",
    "    relevance = similarity * 5.0\n",
    "    \n",
    "    # Generate feedback\n",
    "    feedback_parts = []\n",
    "    if keywords_matched < len(keywords):\n",
    "        missing = [kw for kw in keywords if kw.lower() not in answer_lower]\n",
    "        feedback_parts.append(f\"Missing keywords: {', '.join(missing[:3])}\")\n",
    "    if length_ratio < 0.7:\n",
    "        feedback_parts.append(\"Answer too short - lacks detail\")\n",
    "    elif length_ratio > 1.3:\n",
    "        feedback_parts.append(\"Answer too long - could be more concise\")\n",
    "    if similarity < 0.5:\n",
    "        feedback_parts.append(\"Answer diverges from reference - may have hallucinations\")\n",
    "    \n",
    "    feedback = \" | \".join(feedback_parts) if feedback_parts else \"Good answer!\"\n",
    "    \n",
    "    return AnswerResult(\n",
    "        accuracy=accuracy,\n",
    "        completeness=completeness,\n",
    "        relevance=relevance,\n",
    "        feedback=feedback\n",
    "    ), generated_answer, docs\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EVALUATION LOOP\n",
    "# ============================================================================\n",
    "\n",
    "def run_detailed_evaluation(test_cases, num_tests=None):\n",
    "    \"\"\"\n",
    "    Run detailed evaluation on test cases\n",
    "    \"\"\"\n",
    "    if num_tests:\n",
    "        test_cases = test_cases[:num_tests]\n",
    "    \n",
    "    results = {\n",
    "        'individual_tests': [],\n",
    "        'summary': {}\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DETAILED RAG SYSTEM EVALUATION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total tests to run: {len(test_cases)}\\n\")\n",
    "    \n",
    "    # Track metrics\n",
    "    all_accuracy = []\n",
    "    all_completeness = []\n",
    "    all_relevance = []\n",
    "    all_mrr = []\n",
    "    all_ndcg = []\n",
    "    all_keyword_coverage = []\n",
    "    \n",
    "    for test_number, test in enumerate(test_cases, 1):\n",
    "        # Print test info\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Test #{test_number}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        print(f\"Question: {test['question']}\")\n",
    "        print(f\"Keywords: {test['keywords']}\")\n",
    "        print(f\"Category: {test['category']}\")\n",
    "        print(f\"Reference Answer: {test['reference_answer'][:150]}...\")\n",
    "        \n",
    "        # Retrieval Evaluation\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(\"Retrieval Evaluation\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        \n",
    "        retrieval_result = evaluate_retrieval(\n",
    "            test['question'], \n",
    "            test['keywords']\n",
    "        )\n",
    "        \n",
    "        print(f\"MRR: {retrieval_result.mrr:.4f}\")\n",
    "        print(f\"nDCG: {retrieval_result.ndcg:.4f}\")\n",
    "        print(f\"Keywords Found: {retrieval_result.keywords_found}/{retrieval_result.total_keywords}\")\n",
    "        print(f\"Keyword Coverage: {retrieval_result.keyword_coverage:.1f}%\")\n",
    "        print(f\"\\nRetrieved Documents:\")\n",
    "        for i, doc in enumerate(retrieval_result.retrieved_docs, 1):\n",
    "            print(f\"  {i}. {doc}...\")\n",
    "        \n",
    "        # Answer Evaluation\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(\"Answer Evaluation\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        \n",
    "        answer_result, generated_answer, retrieved_docs = evaluate_answer(\n",
    "            test['question'],\n",
    "            test['reference_answer'],\n",
    "            test['keywords']\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nGenerated Answer:\\n{generated_answer}\")\n",
    "        print(f\"\\nFeedback:\\n{answer_result.feedback}\")\n",
    "        print(\"\\nScores:\")\n",
    "        print(f\"  Accuracy: {answer_result.accuracy:.2f}/5\")\n",
    "        print(f\"  Completeness: {answer_result.completeness:.2f}/5\")\n",
    "        print(f\"  Relevance: {answer_result.relevance:.2f}/5\")\n",
    "        print(f\"  Overall: {(answer_result.accuracy + answer_result.completeness + answer_result.relevance)/3:.2f}/5\")\n",
    "        print(f\"{'=' * 80}\\n\")\n",
    "        \n",
    "        # Store results\n",
    "        results['individual_tests'].append({\n",
    "            'test_number': test_number,\n",
    "            'question': test['question'],\n",
    "            'category': test['category'],\n",
    "            'keywords': test['keywords'],\n",
    "            'generated_answer': generated_answer,\n",
    "            'reference_answer': test['reference_answer'],\n",
    "            'retrieval': {\n",
    "                'mrr': retrieval_result.mrr,\n",
    "                'ndcg': retrieval_result.ndcg,\n",
    "                'keyword_coverage': retrieval_result.keyword_coverage,\n",
    "                'keywords_found': retrieval_result.keywords_found\n",
    "            },\n",
    "            'answer': {\n",
    "                'accuracy': answer_result.accuracy,\n",
    "                'completeness': answer_result.completeness,\n",
    "                'relevance': answer_result.relevance,\n",
    "                'feedback': answer_result.feedback\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Collect metrics\n",
    "        all_accuracy.append(answer_result.accuracy)\n",
    "        all_completeness.append(answer_result.completeness)\n",
    "        all_relevance.append(answer_result.relevance)\n",
    "        all_mrr.append(retrieval_result.mrr)\n",
    "        all_ndcg.append(retrieval_result.ndcg)\n",
    "        all_keyword_coverage.append(retrieval_result.keyword_coverage)\n",
    "    \n",
    "    # Calculate summary\n",
    "    results['summary'] = {\n",
    "        'total_tests': len(test_cases),\n",
    "        'avg_accuracy': sum(all_accuracy) / len(all_accuracy) if all_accuracy else 0,\n",
    "        'avg_completeness': sum(all_completeness) / len(all_completeness) if all_completeness else 0,\n",
    "        'avg_relevance': sum(all_relevance) / len(all_relevance) if all_relevance else 0,\n",
    "        'avg_mrr': sum(all_mrr) / len(all_mrr) if all_mrr else 0,\n",
    "        'avg_ndcg': sum(all_ndcg) / len(all_ndcg) if all_ndcg else 0,\n",
    "        'avg_keyword_coverage': sum(all_keyword_coverage) / len(all_keyword_coverage) if all_keyword_coverage else 0,\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ============================================================================\n",
    "# PRINT SUMMARY REPORT\n",
    "# ============================================================================\n",
    "\n",
    "def print_summary_report(results):\n",
    "    \"\"\"Print summary statistics\"\"\"\n",
    "    summary = results['summary']\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EVALUATION SUMMARY REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal Tests Run: {summary['total_tests']}\")\n",
    "    print(f\"\\nAverage Scores:\")\n",
    "    print(f\"  Accuracy:         {summary['avg_accuracy']:.2f}/5.0\")\n",
    "    print(f\"  Completeness:     {summary['avg_completeness']:.2f}/5.0\")\n",
    "    print(f\"  Relevance:        {summary['avg_relevance']:.2f}/5.0\")\n",
    "    print(f\"  Overall:          {(summary['avg_accuracy'] + summary['avg_completeness'] + summary['avg_relevance'])/3:.2f}/5.0\")\n",
    "    \n",
    "    print(f\"\\nRetrieval Metrics:\")\n",
    "    print(f\"  Mean Reciprocal Rank (MRR): {summary['avg_mrr']:.4f}\")\n",
    "    print(f\"  nDCG (Normalized Gains):    {summary['avg_ndcg']:.4f}\")\n",
    "    print(f\"  Keyword Coverage:           {summary['avg_keyword_coverage']:.1f}%\")\n",
    "    print(f\"\\n{'=' * 80}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE\n",
    "# ============================================================================\n",
    "\n",
    "# Load test data\n",
    "import json\n",
    "test_cases = []\n",
    "with open('tests.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        test_cases.append(json.loads(line.strip()))\n",
    "\n",
    "# Run detailed evaluation (first 5 tests for quick demo)\n",
    "results = run_detailed_evaluation(test_cases, num_tests=None)\n",
    "\n",
    "# Print summary\n",
    "print_summary_report(results)\n",
    "\n",
    "# Save all results\n",
    "with open('detailed_evaluation_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "    print(\"âœ… Saved detailed results to: detailed_evaluation_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8acd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93fb29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6108c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56387a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35d150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
